{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (and Overfitting)\n",
    "\n",
    "\n",
    "\"The Theory Behind Overfitting, Cross Validation, Regularization, Bagging, and Boosting: Tutorial\" (Benyamin Ghojogh, Mark Crowley)\n",
    "https://arxiv.org/abs/1905.12787\n",
    "\n",
    "We already saw `GridSearchCV`. This is an exhaustive approach to optimization and is prone to overfitting.  `RandomSearch` often gives comparable answers but protects, to some degree, overfitting. See \"Random Search for Hyper-Parameter Optimization\"\n",
    "James Bergstra, Yoshua Bengio; 13(Feb):281âˆ’305, 2012 for a theoretical discussion.\n",
    "\n",
    "There are Bayesian-like approaches as well, that seek to minimize an objective function over a large range of parameters.\n",
    "\n",
    "[`hyperopt`](http://hyperopt.github.io/hyperopt/) is one such popular approach, which is used as `hyperas` in `keras` (see e.g., https://arxiv.org/abs/1801.01596)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /Users/jbloom/anaconda3/lib/python3.6/site-packages (0.1.2)\n",
      "Collecting hyperas\n",
      "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (4.19.9)\n",
      "Requirement already satisfied: scipy in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (1.2.1)\n",
      "Requirement already satisfied: future in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: pymongo in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (3.8.0)\n",
      "Requirement already satisfied: six in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: networkx in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (1.11)\n",
      "Requirement already satisfied: numpy in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperopt) (1.16.2)\n",
      "Requirement already satisfied: keras in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperas) (2.2.4)\n",
      "Requirement already satisfied: entrypoints in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperas) (0.2.3)\n",
      "Requirement already satisfied: jupyter in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: nbformat in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperas) (4.4.0)\n",
      "Requirement already satisfied: nbconvert in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from hyperas) (5.3.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from networkx->hyperopt) (4.2.1)\n",
      "Requirement already satisfied: pyyaml in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (3.12)\n",
      "Requirement already satisfied: h5py in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (2.8.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (1.0.6)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (1.0.5)\n",
      "Requirement already satisfied: notebook in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (5.4.0)\n",
      "Requirement already satisfied: qtconsole in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (4.3.1)\n",
      "Requirement already satisfied: jupyter-console in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (5.2.0)\n",
      "Requirement already satisfied: ipykernel in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (4.8.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (7.1.1)\n",
      "Requirement already satisfied: ipython_genutils in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (4.3.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (2.6.0)\n",
      "Requirement already satisfied: jupyter_core in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (4.4.0)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.9.6)\n",
      "Requirement already satisfied: pygments in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.2.0)\n",
      "Requirement already satisfied: bleach in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied: testpath in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (0.3.1)\n",
      "Requirement already satisfied: tornado>=4 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (4.5.3)\n",
      "Requirement already satisfied: jupyter_client>=5.2.0 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (5.2.2)\n",
      "Requirement already satisfied: Send2Trash in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (1.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
      "Requirement already satisfied: ipython in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter-console->jupyter->hyperas) (5.6.0)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.0 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter-console->jupyter->hyperas) (1.0.15)\n",
      "Requirement already satisfied: widgetsnbextension~=3.1.0 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipywidgets->jupyter->hyperas) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jinja2->nbconvert->hyperas) (1.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from bleach->nbconvert->hyperas) (1.0.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter_client>=5.2.0->notebook->jupyter->hyperas) (16.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from jupyter_client>=5.2.0->notebook->jupyter->hyperas) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (39.1.0)\n",
      "Requirement already satisfied: pickleshare in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
      "Requirement already satisfied: appnope in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (4.3.1)\n",
      "Requirement already satisfied: wcwidth in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from prompt_toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
      "Requirement already satisfied: webencodings in /Users/jbloom/anaconda3/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->hyperas) (0.5.1)\n",
      "Installing collected packages: hyperas\n",
      "Successfully installed hyperas-0.4.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install hyperopt hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# see http://maxpumperla.com/hyperas/\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "\n",
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train.reshape(60000, 784)\n",
    "    X_test = X_test.reshape(10000, 784)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    nb_classes = 10\n",
    "    Y_train = to_categorical(y_train, nb_classes)\n",
    "    Y_test = to_categorical(y_test, nb_classes)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              nb_epoch=1,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "\n",
      "W0606 22:48:08.857167 140735763825472 nn_ops.py:4224] Large dropout rate: 0.73717 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0606 22:48:08.921252 140735763825472 nn_ops.py:4224] Large dropout rate: 0.651797 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0606 22:48:08.985095 140735763825472 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "W0606 22:48:09.051643 140735763825472 deprecation.py:323] From /Users/jbloom/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "  128/60000 [..............................]\n",
      " - ETA: 55s - loss: 3.2828\n",
      "\n",
      " 1152/60000 [..............................]\n",
      " - ETA: 8s - loss: 2.9537 \n",
      "\b\n",
      " 2176/60000 [>.............................]\n",
      " - ETA: 6s - loss: 2.8517\n",
      "\b\n",
      " 3200/60000 [>.............................]\n",
      " - ETA: 4s - loss: 2.8160\n",
      "\b\n",
      " 4224/60000 [=>............................]\n",
      " - ETA: 4s - loss: 2.7767\n",
      "\b\n",
      " 5120/60000 [=>............................]\n",
      " - ETA: 4s - loss: 2.7546\n",
      "\b\n",
      " 6016/60000 [==>...........................]\n",
      " - ETA: 3s - loss: 2.7467\n",
      "\b\n",
      " 6912/60000 [==>...........................]\n",
      " - ETA: 3s - loss: 2.7330\n",
      "\b\n",
      " 7808/60000 [==>...........................]\n",
      " - ETA: 3s - loss: 2.7266\n",
      "\b\n",
      " 8704/60000 [===>..........................]\n",
      " - ETA: 3s - loss: 2.7180\n",
      "\b\n",
      " 9600/60000 [===>..........................]\n",
      " - ETA: 3s - loss: 2.7114\n",
      "\b\n",
      "10496/60000 [====>.........................]\n",
      " - ETA: 3s - loss: 2.7012\n",
      "\b\n",
      "11520/60000 [====>.........................]\n",
      " - ETA: 3s - loss: 2.6934\n",
      "\b\n",
      "12672/60000 [=====>........................]\n",
      " - ETA: 3s - loss: 2.6877\n",
      "\b\n",
      "13696/60000 [=====>........................]\n",
      " - ETA: 2s - loss: 2.6821\n",
      "\b\n",
      "14592/60000 [======>.......................]\n",
      " - ETA: 2s - loss: 2.6756\n",
      "\b\n",
      "15616/60000 [======>.......................]\n",
      " - ETA: 2s - loss: 2.6686\n",
      "\b\n",
      "16512/60000 [=======>......................]\n",
      " - ETA: 2s - loss: 2.6638\n",
      "\b\n",
      "17408/60000 [=======>......................]\n",
      " - ETA: 2s - loss: 2.6561\n",
      "\b\n",
      "18304/60000 [========>.....................]\n",
      " - ETA: 2s - loss: 2.6493\n",
      "\b\n",
      "19200/60000 [========>.....................]\n",
      " - ETA: 2s - loss: 2.6443\n",
      "\b\n",
      "20224/60000 [=========>....................]\n",
      " - ETA: 2s - loss: 2.6358\n",
      "\b\n",
      "21120/60000 [=========>....................]\n",
      " - ETA: 2s - loss: 2.6328\n",
      "\b\n",
      "22272/60000 [==========>...................]\n",
      " - ETA: 2s - loss: 2.6279\n",
      "\b\n",
      "23424/60000 [==========>...................]\n",
      " - ETA: 2s - loss: 2.6215\n",
      "\b\n",
      "24448/60000 [===========>..................]\n",
      " - ETA: 2s - loss: 2.6161\n",
      "\b\n",
      "25344/60000 [===========>..................]\n",
      " - ETA: 2s - loss: 2.6101\n",
      "\b\n",
      "26112/60000 [============>.................]\n",
      " - ETA: 2s - loss: 2.6074\n",
      "\b\n",
      "27008/60000 [============>.................]\n",
      " - ETA: 2s - loss: 2.6046\n",
      "\b\n",
      "27904/60000 [============>.................]\n",
      " - ETA: 1s - loss: 2.6021\n",
      "\b\n",
      "28928/60000 [=============>................]\n",
      " - ETA: 1s - loss: 2.5976\n",
      "\b\n",
      "29568/60000 [=============>................]\n",
      " - ETA: 1s - loss: 2.5947\n",
      "\b\n",
      "30464/60000 [==============>...............]\n",
      " - ETA: 1s - loss: 2.5901\n",
      "\b\n",
      "31488/60000 [==============>...............]\n",
      " - ETA: 1s - loss: 2.5859\n",
      "\b\n",
      "32512/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 2.5804\n",
      "\b\n",
      "33664/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 2.5751\n",
      "\b\n",
      "34816/60000 [================>.............]\n",
      " - ETA: 1s - loss: 2.5702\n",
      "\b\n",
      "35712/60000 [================>.............]\n",
      " - ETA: 1s - loss: 2.5665\n",
      "\b\n",
      "36608/60000 [=================>............]\n",
      " - ETA: 1s - loss: 2.5623\n",
      "\b\n",
      "37504/60000 [=================>............]\n",
      " - ETA: 1s - loss: 2.5590\n",
      "\b\n",
      "38528/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 2.5533\n",
      "\b\n",
      "39424/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 2.5485\n",
      "\b\n",
      "40448/60000 [===================>..........]\n",
      " - ETA: 1s - loss: 2.5448\n",
      "\b\n",
      "41472/60000 [===================>..........]\n",
      " - ETA: 1s - loss: 2.5408\n",
      "\b\n",
      "42368/60000 [====================>.........]\n",
      " - ETA: 1s - loss: 2.5359\n",
      "\b\n",
      "43264/60000 [====================>.........]\n",
      " - ETA: 0s - loss: 2.5320\n",
      "\b\n",
      "44160/60000 [=====================>........]\n",
      " - ETA: 0s - loss: 2.5272\n",
      "\b\n",
      "45056/60000 [=====================>........]\n",
      " - ETA: 0s - loss: 2.5230\n",
      "\b\n",
      "45952/60000 [=====================>........]\n",
      " - ETA: 0s - loss: 2.5192\n",
      "\b\n",
      "46848/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 2.5147\n",
      "\b\n",
      "47744/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 2.5121\n",
      "\b\n",
      "48512/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 2.5092\n",
      "\b\n",
      "49408/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 2.5052\n",
      "\b\n",
      "50304/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 2.5015\n",
      "\b\n",
      "51200/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 2.4978\n",
      "\b\n",
      "52224/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 2.4925\n",
      "\b\n",
      "53248/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 2.4871\n",
      "\b\n",
      "54144/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 2.4834\n",
      "\b\n",
      "55040/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 2.4797\n",
      "\b\n",
      "55936/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 2.4751\n",
      "\b\n",
      "56832/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 2.4712\n",
      "\b\n",
      "57728/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 2.4679\n",
      "\b\n",
      "58752/60000 [============================>.]\n",
      " - ETA: 0s - loss: 2.4633\n",
      "\b\n",
      "59776/60000 [============================>.]\n",
      " - ETA: 0s - loss: 2.4581\n",
      "\b\n",
      "60000/60000 [==============================]\n",
      " - 4s 66us/sample - loss: 2.4570 - val_loss: 1.8748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 22:48:13.906703 140735763825472 nn_ops.py:4224] Large dropout rate: 0.836667 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0606 22:48:14.045001 140735763825472 nn_ops.py:4224] Large dropout rate: 0.912829 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\n",
      "1.8747559463500976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 22:48:14.109874 140735763825472 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "   64/60000 [..............................]\n",
      " - ETA: 2:22 - loss: 4.0212\n",
      "\b\n",
      "  384/60000 [..............................]\n",
      " - ETA: 31s - loss: 3.3269 \n",
      "\n",
      "  768/60000 [..............................]\n",
      " - ETA: 19s - loss: 3.0616\n",
      "\n",
      " 1152/60000 [..............................]\n",
      " - ETA: 15s - loss: 2.9117\n",
      "\n",
      " 1472/60000 [..............................]\n",
      " - ETA: 14s - loss: 2.8174\n",
      "\n",
      " 1792/60000 [..............................]\n",
      " - ETA: 13s - loss: 2.7429\n",
      "\n",
      " 2176/60000 [>.............................]\n",
      " - ETA: 12s - loss: 2.6709\n",
      "\n",
      " 2496/60000 [>.............................]\n",
      " - ETA: 12s - loss: 2.6121\n",
      "\n",
      " 2816/60000 [>.............................]\n",
      " - ETA: 11s - loss: 2.5693\n",
      "\n",
      " 3136/60000 [>.............................]\n",
      " - ETA: 11s - loss: 2.5308\n",
      "\n",
      " 3456/60000 [>.............................]\n",
      " - ETA: 11s - loss: 2.4910\n",
      "\n",
      " 3776/60000 [>.............................]\n",
      " - ETA: 11s - loss: 2.4535\n",
      "\n",
      " 4096/60000 [=>............................]\n",
      " - ETA: 10s - loss: 2.4223\n",
      "\n",
      " 4480/60000 [=>............................]\n",
      " - ETA: 10s - loss: 2.3820\n",
      "\n",
      " 4864/60000 [=>............................]\n",
      " - ETA: 10s - loss: 2.3498\n",
      "\n",
      " 5184/60000 [=>............................]\n",
      " - ETA: 10s - loss: 2.3244\n",
      "\n",
      " 5504/60000 [=>............................]\n",
      " - ETA: 10s - loss: 2.3011\n",
      "\n",
      " 5824/60000 [=>............................]\n",
      " - ETA: 9s - loss: 2.2675 \n",
      "\b\n",
      " 6144/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.2413\n",
      "\b\n",
      " 6464/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.2141\n",
      "\b\n",
      " 6848/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.1798\n",
      "\b\n",
      " 7168/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.1536\n",
      "\b\n",
      " 7488/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.1312\n",
      "\b\n",
      " 7808/60000 [==>...........................]\n",
      " - ETA: 9s - loss: 2.1058\n",
      "\b\n",
      " 8128/60000 [===>..........................]\n",
      " - ETA: 9s - loss: 2.0849\n",
      "\b\n",
      " 8448/60000 [===>..........................]\n",
      " - ETA: 9s - loss: 2.0653\n",
      "\b\n",
      " 8768/60000 [===>..........................]\n",
      " - ETA: 9s - loss: 2.0436\n",
      "\b\n",
      " 9088/60000 [===>..........................]\n",
      " - ETA: 8s - loss: 2.0215\n",
      "\b\n",
      " 9408/60000 [===>..........................]\n",
      " - ETA: 8s - loss: 2.0025\n",
      "\b\n",
      " 9728/60000 [===>..........................]\n",
      " - ETA: 8s - loss: 1.9795\n",
      "\b\n",
      "10112/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.9534\n",
      "\b\n",
      "10496/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.9296\n",
      "\b\n",
      "10880/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.9071\n",
      "\b\n",
      "11264/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.8874\n",
      "\b\n",
      "11584/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.8684\n",
      "\b\n",
      "11904/60000 [====>.........................]\n",
      " - ETA: 8s - loss: 1.8545\n",
      "\b\n",
      "12288/60000 [=====>........................]\n",
      " - ETA: 8s - loss: 1.8338\n",
      "\b\n",
      "12608/60000 [=====>........................]\n",
      " - ETA: 8s - loss: 1.8185\n",
      "\b\n",
      "12992/60000 [=====>........................]\n",
      " - ETA: 7s - loss: 1.7991\n",
      "\b\n",
      "13376/60000 [=====>........................]\n",
      " - ETA: 7s - loss: 1.7800\n",
      "\b\n",
      "13760/60000 [=====>........................]\n",
      " - ETA: 7s - loss: 1.7618\n",
      "\b\n",
      "14144/60000 [======>.......................]\n",
      " - ETA: 7s - loss: 1.7444\n",
      "\b\n",
      "14592/60000 [======>.......................]\n",
      " - ETA: 7s - loss: 1.7271\n",
      "\b\n",
      "14976/60000 [======>.......................]\n",
      " - ETA: 7s - loss: 1.7102\n",
      "\b\n",
      "15424/60000 [======>.......................]\n",
      " - ETA: 7s - loss: 1.6906\n",
      "\b\n",
      "15808/60000 [======>.......................]\n",
      " - ETA: 7s - loss: 1.6749\n",
      "\b\n",
      "16128/60000 [=======>......................]\n",
      " - ETA: 7s - loss: 1.6646\n",
      "\b\n",
      "16448/60000 [=======>......................]\n",
      " - ETA: 7s - loss: 1.6534\n",
      "\b\n",
      "16768/60000 [=======>......................]\n",
      " - ETA: 7s - loss: 1.6396\n",
      "\b\n",
      "17088/60000 [=======>......................]\n",
      " - ETA: 7s - loss: 1.6270\n",
      "\b\n",
      "17472/60000 [=======>......................]\n",
      " - ETA: 6s - loss: 1.6116\n",
      "\b\n",
      "17856/60000 [=======>......................]\n",
      " - ETA: 6s - loss: 1.5983\n",
      "\b\n",
      "18240/60000 [========>.....................]\n",
      " - ETA: 6s - loss: 1.5851\n",
      "\b\n",
      "18624/60000 [========>.....................]\n",
      " - ETA: 6s - loss: 1.5710\n",
      "\b\n",
      "19072/60000 [========>.....................]\n",
      " - ETA: 6s - loss: 1.5551\n",
      "\b\n",
      "19456/60000 [========>.....................]\n",
      " - ETA: 6s - loss: 1.5441\n",
      "\b\n",
      "19776/60000 [========>.....................]\n",
      " - ETA: 6s - loss: 1.5354\n",
      "\b\n",
      "20160/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.5268\n",
      "\b\n",
      "20544/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.5146\n",
      "\b\n",
      "20864/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.5044\n",
      "\b\n",
      "21184/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.4965\n",
      "\b\n",
      "21504/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.4864\n",
      "\b\n",
      "21824/60000 [=========>....................]\n",
      " - ETA: 6s - loss: 1.4769\n",
      "\b\n",
      "22080/60000 [==========>...................]\n",
      " - ETA: 6s - loss: 1.4701\n",
      "\b\n",
      "22400/60000 [==========>...................]\n",
      " - ETA: 6s - loss: 1.4603\n",
      "\b\n",
      "22720/60000 [==========>...................]\n",
      " - ETA: 6s - loss: 1.4516\n",
      "\b\n",
      "23040/60000 [==========>...................]\n",
      " - ETA: 5s - loss: 1.4440\n",
      "\b\n",
      "23360/60000 [==========>...................]\n",
      " - ETA: 5s - loss: 1.4343\n",
      "\b\n",
      "23680/60000 [==========>...................]\n",
      " - ETA: 5s - loss: 1.4272\n",
      "\b\n",
      "24000/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.4189\n",
      "\b\n",
      "24320/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.4124\n",
      "\b\n",
      "24768/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.4027\n",
      "\b\n",
      "25152/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.3942\n",
      "\b\n",
      "25472/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.3885\n",
      "\b\n",
      "25728/60000 [===========>..................]\n",
      " - ETA: 5s - loss: 1.3837\n",
      "\b\n",
      "26112/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3753\n",
      "\b\n",
      "26496/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3666\n",
      "\b\n",
      "26944/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3565\n",
      "\b\n",
      "27264/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3523\n",
      "\b\n",
      "27584/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3476\n",
      "\b\n",
      "27904/60000 [============>.................]\n",
      " - ETA: 5s - loss: 1.3414\n",
      "\b\n",
      "28224/60000 [=============>................]\n",
      " - ETA: 5s - loss: 1.3344\n",
      "\b\n",
      "28544/60000 [=============>................]\n",
      " - ETA: 5s - loss: 1.3282\n",
      "\b\n",
      "28928/60000 [=============>................]\n",
      " - ETA: 4s - loss: 1.3212\n",
      "\b\n",
      "29312/60000 [=============>................]\n",
      " - ETA: 4s - loss: 1.3151\n",
      "\b\n",
      "29696/60000 [=============>................]\n",
      " - ETA: 4s - loss: 1.3079\n",
      "\b\n",
      "30080/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.3025\n",
      "\b\n",
      "30528/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.2950\n",
      "\b\n",
      "30912/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.2891\n",
      "\b\n",
      "31232/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.2846\n",
      "\b\n",
      "31552/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.2786\n",
      "\b\n",
      "31872/60000 [==============>...............]\n",
      " - ETA: 4s - loss: 1.2735\n",
      "\b\n",
      "32192/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2689\n",
      "\b\n",
      "32512/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2630\n",
      "\b\n",
      "32896/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2580\n",
      "\b\n",
      "33280/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2526\n",
      "\b\n",
      "33600/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2466\n",
      "\b\n",
      "33920/60000 [===============>..............]\n",
      " - ETA: 4s - loss: 1.2417\n",
      "\b\n",
      "34240/60000 [================>.............]\n",
      " - ETA: 4s - loss: 1.2367\n",
      "\b\n",
      "34624/60000 [================>.............]\n",
      " - ETA: 4s - loss: 1.2303\n",
      "\b\n",
      "35008/60000 [================>.............]\n",
      " - ETA: 3s - loss: 1.2246\n",
      "\b\n",
      "35328/60000 [================>.............]\n",
      " - ETA: 3s - loss: 1.2185\n",
      "\b\n",
      "35712/60000 [================>.............]\n",
      " - ETA: 3s - loss: 1.2127\n",
      "\b\n",
      "36096/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.2076\n",
      "\b\n",
      "36352/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.2050\n",
      "\b\n",
      "36672/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.2015\n",
      "\b\n",
      "37056/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.1958\n",
      "\b\n",
      "37376/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.1914\n",
      "\b\n",
      "37696/60000 [=================>............]\n",
      " - ETA: 3s - loss: 1.1880\n",
      "\b\n",
      "38016/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1843\n",
      "\b\n",
      "38336/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1809\n",
      "\b\n",
      "38592/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\n",
      "38912/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1737\n",
      "\b\n",
      "39232/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1684\n",
      "\b\n",
      "39552/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1652\n",
      "\b\n",
      "39872/60000 [==================>...........]\n",
      " - ETA: 3s - loss: 1.1621\n",
      "\b\n",
      "40192/60000 [===================>..........]\n",
      " - ETA: 3s - loss: 1.1578\n",
      "\b\n",
      "40512/60000 [===================>..........]\n",
      " - ETA: 3s - loss: 1.1537\n",
      "\b\n",
      "40832/60000 [===================>..........]\n",
      " - ETA: 3s - loss: 1.1505\n",
      "\b\n",
      "41088/60000 [===================>..........]\n",
      " - ETA: 3s - loss: 1.1473\n",
      "\b\n",
      "41408/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.1431\n",
      "\b\n",
      "41728/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.1395\n",
      "\b\n",
      "42112/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1353\n",
      "\b\n",
      "42496/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1304\n",
      "\b\n",
      "42880/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1256\n",
      "\b\n",
      "43200/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1212\n",
      "\b\n",
      "43520/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1171\n",
      "\b\n",
      "43904/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.1143\n",
      "\b\n",
      "44288/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.1100\n",
      "\b\n",
      "44608/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.1071\n",
      "\b\n",
      "44928/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.1036\n",
      "\b\n",
      "45312/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.0995\n",
      "\b\n",
      "45632/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.0966\n",
      "\b\n",
      "45952/60000 [=====================>........]\n",
      " - ETA: 2s - loss: 1.0942\n",
      "\b\n",
      "46272/60000 [======================>.......]\n",
      " - ETA: 2s - loss: 1.0907\n",
      "\b\n",
      "46592/60000 [======================>.......]\n",
      " - ETA: 2s - loss: 1.0874\n",
      "\b\n",
      "46976/60000 [======================>.......]\n",
      " - ETA: 2s - loss: 1.0839\n",
      "\b\n",
      "47168/60000 [======================>.......]\n",
      " - ETA: 2s - loss: 1.0819\n",
      "\b\n",
      "47424/60000 [======================>.......]\n",
      " - ETA: 2s - loss: 1.0795\n",
      "\b\n",
      "47744/60000 [======================>.......]\n",
      " - ETA: 1s - loss: 1.0772\n",
      "\b\n",
      "48000/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0752\n",
      "\b\n",
      "48320/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0719\n",
      "\b\n",
      "48576/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0707\n",
      "\b\n",
      "48896/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0682\n",
      "\b\n",
      "49152/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0666\n",
      "\b\n",
      "49408/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0648\n",
      "\b\n",
      "49728/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.0620\n",
      "\b\n",
      "50048/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0586\n",
      "\b\n",
      "50368/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0554\n",
      "\b\n",
      "50688/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0520\n",
      "\b\n",
      "51072/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0496\n",
      "\b\n",
      "51392/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0466\n",
      "\b\n",
      "51648/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0449\n",
      "\b\n",
      "51904/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.0422\n",
      "\b\n",
      "52224/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0392\n",
      "\b\n",
      "52544/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0366\n",
      "\b\n",
      "52864/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0341\n",
      "\b\n",
      "53184/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0308\n",
      "\b\n",
      "53440/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0292\n",
      "\b\n",
      "53760/60000 [=========================>....]\n",
      " - ETA: 1s - loss: 1.0272\n",
      "\b\n",
      "54080/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0253\n",
      "\b\n",
      "54400/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0229\n",
      "\b\n",
      "54720/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0202\n",
      "\b\n",
      "55040/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0191\n",
      "\b\n",
      "55360/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0183\n",
      "\b\n",
      "55616/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0172\n",
      "\b\n",
      "55936/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.0149\n",
      "\b\n",
      "56256/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0132\n",
      "\b\n",
      "56576/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0110\n",
      "\b\n",
      "56896/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0084\n",
      "\b\n",
      "57216/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0055\n",
      "\b\n",
      "57600/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0034\n",
      "\b\n",
      "57920/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.0013\n",
      "\b\n",
      "58240/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9979\n",
      "\b\n",
      "58560/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9963\n",
      "\b\n",
      "58880/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9940\n",
      "\b\n",
      "59200/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9920\n",
      "\b\n",
      "59520/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9900\n",
      "\b\n",
      "59840/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.9886\n",
      "\b\n",
      "60000/60000 [==============================]\n",
      " - 11s 176us/sample - loss: 0.9878 - val_loss: 0.3117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 22:48:25.710746 140735763825472 nn_ops.py:4224] Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0606 22:48:25.808398 140735763825472 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\n",
      "0.31170902903676034\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "   64/60000 [..............................]\n",
      " - ETA: 1:52 - loss: 3.3697\n",
      "\b\n",
      "  576/60000 [..............................]\n",
      " - ETA: 17s - loss: 2.9777 \n",
      "\n",
      " 1024/60000 [..............................]\n",
      " - ETA: 12s - loss: 2.8745\n",
      "\n",
      " 1472/60000 [..............................]\n",
      " - ETA: 11s - loss: 2.7416\n",
      "\n",
      " 1856/60000 [..............................]\n",
      " - ETA: 10s - loss: 2.6849\n",
      "\n",
      " 2240/60000 [>.............................]\n",
      " - ETA: 9s - loss: 2.6222 \n",
      "\b\n",
      " 2688/60000 [>.............................]\n",
      " - ETA: 9s - loss: 2.5683\n",
      "\b\n",
      " 3200/60000 [>.............................]\n",
      " - ETA: 8s - loss: 2.5135\n",
      "\b\n",
      " 3712/60000 [>.............................]\n",
      " - ETA: 8s - loss: 2.4602\n",
      "\b\n",
      " 4288/60000 [=>............................]\n",
      " - ETA: 7s - loss: 2.4140\n",
      "\b\n",
      " 4800/60000 [=>............................]\n",
      " - ETA: 7s - loss: 2.3834\n",
      "\b\n",
      " 5312/60000 [=>............................]\n",
      " - ETA: 7s - loss: 2.3585\n",
      "\b\n",
      " 5824/60000 [=>............................]\n",
      " - ETA: 6s - loss: 2.3341\n",
      "\b\n",
      " 6336/60000 [==>...........................]\n",
      " - ETA: 6s - loss: 2.3060\n",
      "\b\n",
      " 6912/60000 [==>...........................]\n",
      " - ETA: 6s - loss: 2.2826\n",
      "\b\n",
      " 7424/60000 [==>...........................]\n",
      " - ETA: 6s - loss: 2.2646\n",
      "\b\n",
      " 7872/60000 [==>...........................]\n",
      " - ETA: 6s - loss: 2.2496\n",
      "\b\n",
      " 8320/60000 [===>..........................]\n",
      " - ETA: 6s - loss: 2.2389\n",
      "\b\n",
      " 8768/60000 [===>..........................]\n",
      " - ETA: 6s - loss: 2.2262\n",
      "\b\n",
      " 9216/60000 [===>..........................]\n",
      " - ETA: 6s - loss: 2.2114\n",
      "\b\n",
      " 9664/60000 [===>..........................]\n",
      " - ETA: 6s - loss: 2.1949\n",
      "\b\n",
      "10112/60000 [====>.........................]\n",
      " - ETA: 6s - loss: 2.1866\n",
      "\b\n",
      "10560/60000 [====>.........................]\n",
      " - ETA: 5s - loss: 2.1731\n",
      "\b\n",
      "11008/60000 [====>.........................]\n",
      " - ETA: 5s - loss: 2.1610\n",
      "\b\n",
      "11520/60000 [====>.........................]\n",
      " - ETA: 5s - loss: 2.1488\n",
      "\b\n",
      "11968/60000 [====>.........................]\n",
      " - ETA: 5s - loss: 2.1415\n",
      "\b\n",
      "12416/60000 [=====>........................]\n",
      " - ETA: 5s - loss: 2.1314\n",
      "\b\n",
      "12864/60000 [=====>........................]\n",
      " - ETA: 5s - loss: 2.1243\n",
      "\b\n",
      "13312/60000 [=====>........................]\n",
      " - ETA: 5s - loss: 2.1137\n",
      "\b\n",
      "13760/60000 [=====>........................]\n",
      " - ETA: 5s - loss: 2.1033\n",
      "\b\n",
      "14208/60000 [======>.......................]\n",
      " - ETA: 5s - loss: 2.0992\n",
      "\b\n",
      "14720/60000 [======>.......................]\n",
      " - ETA: 5s - loss: 2.0889\n",
      "\b\n",
      "15168/60000 [======>.......................]\n",
      " - ETA: 5s - loss: 2.0829\n",
      "\b\n",
      "15616/60000 [======>.......................]\n",
      " - ETA: 5s - loss: 2.0756\n",
      "\b\n",
      "16064/60000 [=======>......................]\n",
      " - ETA: 5s - loss: 2.0666\n",
      "\b\n",
      "16512/60000 [=======>......................]\n",
      " - ETA: 5s - loss: 2.0599\n",
      "\b\n",
      "16960/60000 [=======>......................]\n",
      " - ETA: 5s - loss: 2.0557\n",
      "\b\n",
      "17408/60000 [=======>......................]\n",
      " - ETA: 5s - loss: 2.0490\n",
      "\b\n",
      "17920/60000 [=======>......................]\n",
      " - ETA: 5s - loss: 2.0426\n",
      "\b\n",
      "18368/60000 [========>.....................]\n",
      " - ETA: 5s - loss: 2.0367\n",
      "\b\n",
      "18752/60000 [========>.....................]\n",
      " - ETA: 4s - loss: 2.0320\n",
      "\b\n",
      "19200/60000 [========>.....................]\n",
      " - ETA: 4s - loss: 2.0274\n",
      "\b\n",
      "19648/60000 [========>.....................]\n",
      " - ETA: 4s - loss: 2.0225\n",
      "\b\n",
      "20160/60000 [=========>....................]\n",
      " - ETA: 4s - loss: 2.0164\n",
      "\b\n",
      "20736/60000 [=========>....................]\n",
      " - ETA: 4s - loss: 2.0072\n",
      "\b\n",
      "21248/60000 [=========>....................]\n",
      " - ETA: 4s - loss: 2.0023\n",
      "\b\n",
      "21760/60000 [=========>....................]\n",
      " - ETA: 4s - loss: 1.9963\n",
      "\b\n",
      "22208/60000 [==========>...................]\n",
      " - ETA: 4s - loss: 1.9936\n",
      "\b\n",
      "22656/60000 [==========>...................]\n",
      " - ETA: 4s - loss: 1.9880\n",
      "\b\n",
      "23168/60000 [==========>...................]\n",
      " - ETA: 4s - loss: 1.9839\n",
      "\b\n",
      "23680/60000 [==========>...................]\n",
      " - ETA: 4s - loss: 1.9769\n",
      "\b\n",
      "24192/60000 [===========>..................]\n",
      " - ETA: 4s - loss: 1.9717\n",
      "\b\n",
      "24640/60000 [===========>..................]\n",
      " - ETA: 4s - loss: 1.9674\n",
      "\b\n",
      "25088/60000 [===========>..................]\n",
      " - ETA: 4s - loss: 1.9643\n",
      "\b\n",
      "25536/60000 [===========>..................]\n",
      " - ETA: 4s - loss: 1.9611\n",
      "\b\n",
      "25920/60000 [===========>..................]\n",
      " - ETA: 4s - loss: 1.9570\n",
      "\b\n",
      "26304/60000 [============>.................]\n",
      " - ETA: 3s - loss: 1.9548\n",
      "\b\n",
      "26816/60000 [============>.................]\n",
      " - ETA: 3s - loss: 1.9505\n",
      "\b\n",
      "27328/60000 [============>.................]\n",
      " - ETA: 3s - loss: 1.9463\n",
      "\b\n",
      "27840/60000 [============>.................]\n",
      " - ETA: 3s - loss: 1.9422\n",
      "\b\n",
      "28352/60000 [=============>................]\n",
      " - ETA: 3s - loss: 1.9379\n",
      "\b\n",
      "28864/60000 [=============>................]\n",
      " - ETA: 3s - loss: 1.9337\n",
      "\b\n",
      "29312/60000 [=============>................]\n",
      " - ETA: 3s - loss: 1.9297\n",
      "\b\n",
      "29760/60000 [=============>................]\n",
      " - ETA: 3s - loss: 1.9247\n",
      "\b\n",
      "30144/60000 [==============>...............]\n",
      " - ETA: 3s - loss: 1.9219\n",
      "\b\n",
      "30528/60000 [==============>...............]\n",
      " - ETA: 3s - loss: 1.9197\n",
      "\b\n",
      "30912/60000 [==============>...............]\n",
      " - ETA: 3s - loss: 1.9175\n",
      "\b\n",
      "31232/60000 [==============>...............]\n",
      " - ETA: 3s - loss: 1.9155\n",
      "\b\n",
      "31616/60000 [==============>...............]\n",
      " - ETA: 3s - loss: 1.9137\n",
      "\b\n",
      "32064/60000 [===============>..............]\n",
      " - ETA: 3s - loss: 1.9101\n",
      "\b\n",
      "32512/60000 [===============>..............]\n",
      " - ETA: 3s - loss: 1.9055\n",
      "\b\n",
      "32960/60000 [===============>..............]\n",
      " - ETA: 3s - loss: 1.9038\n",
      "\b\n",
      "33408/60000 [===============>..............]\n",
      " - ETA: 3s - loss: 1.9001\n",
      "\b\n",
      "33856/60000 [===============>..............]\n",
      " - ETA: 3s - loss: 1.8964\n",
      "\b\n",
      "34304/60000 [================>.............]\n",
      " - ETA: 3s - loss: 1.8928\n",
      "\b\n",
      "34752/60000 [================>.............]\n",
      " - ETA: 3s - loss: 1.8883\n",
      "\b\n",
      "35200/60000 [================>.............]\n",
      " - ETA: 2s - loss: 1.8842\n",
      "\b\n",
      "35648/60000 [================>.............]\n",
      " - ETA: 2s - loss: 1.8797\n",
      "\b\n",
      "36160/60000 [=================>............]\n",
      " - ETA: 2s - loss: 1.8769\n",
      "\b\n",
      "36608/60000 [=================>............]\n",
      " - ETA: 2s - loss: 1.8745\n",
      "\b\n",
      "37056/60000 [=================>............]\n",
      " - ETA: 2s - loss: 1.8721\n",
      "\b\n",
      "37504/60000 [=================>............]\n",
      " - ETA: 2s - loss: 1.8695\n",
      "\b\n",
      "37952/60000 [=================>............]\n",
      " - ETA: 2s - loss: 1.8677\n",
      "\b\n",
      "38464/60000 [==================>...........]\n",
      " - ETA: 2s - loss: 1.8650\n",
      "\b\n",
      "38912/60000 [==================>...........]\n",
      " - ETA: 2s - loss: 1.8627\n",
      "\b\n",
      "39232/60000 [==================>...........]\n",
      " - ETA: 2s - loss: 1.8604\n",
      "\b\n",
      "39552/60000 [==================>...........]\n",
      " - ETA: 2s - loss: 1.8580\n",
      "\b\n",
      "39936/60000 [==================>...........]\n",
      " - ETA: 2s - loss: 1.8570\n",
      "\b\n",
      "40384/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.8539\n",
      "\b\n",
      "40832/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.8516\n",
      "\b\n",
      "41344/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.8490\n",
      "\b\n",
      "41792/60000 [===================>..........]\n",
      " - ETA: 2s - loss: 1.8473\n",
      "\b\n",
      "42240/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.8453\n",
      "\b\n",
      "42752/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.8421\n",
      "\b\n",
      "43200/60000 [====================>.........]\n",
      " - ETA: 2s - loss: 1.8399\n",
      "\b\n",
      "43648/60000 [====================>.........]\n",
      " - ETA: 1s - loss: 1.8380\n",
      "\b\n",
      "44096/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 1.8351\n",
      "\b\n",
      "44544/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 1.8344\n",
      "\b\n",
      "44992/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 1.8317\n",
      "\b\n",
      "45440/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 1.8299\n",
      "\b\n",
      "45824/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 1.8287\n",
      "\b\n",
      "46272/60000 [======================>.......]\n",
      " - ETA: 1s - loss: 1.8267\n",
      "\b\n",
      "46720/60000 [======================>.......]\n",
      " - ETA: 1s - loss: 1.8250\n",
      "\b\n",
      "47168/60000 [======================>.......]\n",
      " - ETA: 1s - loss: 1.8233\n",
      "\b\n",
      "47616/60000 [======================>.......]\n",
      " - ETA: 1s - loss: 1.8209\n",
      "\b\n",
      "48128/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.8178\n",
      "\b\n",
      "48576/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.8156\n",
      "\b\n",
      "49088/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.8134\n",
      "\b\n",
      "49472/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.8116\n",
      "\b\n",
      "49792/60000 [=======================>......]\n",
      " - ETA: 1s - loss: 1.8101\n",
      "\b\n",
      "50112/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.8088\n",
      "\b\n",
      "50432/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.8071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\n",
      "50752/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.8048\n",
      "\b\n",
      "51136/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.8031\n",
      "\b\n",
      "51520/60000 [========================>.....]\n",
      " - ETA: 1s - loss: 1.8013\n",
      "\b\n",
      "51904/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 1.7986\n",
      "\b\n",
      "52288/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 1.7975\n",
      "\b\n",
      "52672/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 1.7960\n",
      "\b\n",
      "53056/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 1.7944\n",
      "\b\n",
      "53504/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 1.7930\n",
      "\b\n",
      "53952/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 1.7918\n",
      "\b\n",
      "54464/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.7889\n",
      "\b\n",
      "54848/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.7873\n",
      "\b\n",
      "55104/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.7863\n",
      "\b\n",
      "55424/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.7839\n",
      "\b\n",
      "55808/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 1.7826\n",
      "\b\n",
      "56192/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.7804\n",
      "\b\n",
      "56576/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.7788\n",
      "\b\n",
      "57024/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.7771\n",
      "\b\n",
      "57408/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.7762\n",
      "\b\n",
      "57792/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 1.7750\n",
      "\b\n",
      "58112/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7733\n",
      "\b\n",
      "58368/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7730\n",
      "\b\n",
      "58688/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7717\n",
      "\b\n",
      "59008/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7714\n",
      "\b\n",
      "59392/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7701\n",
      "\b\n",
      "59840/60000 [============================>.]\n",
      " - ETA: 0s - loss: 1.7684\n",
      "\b\n",
      "60000/60000 [==============================]\n",
      " - 8s 136us/sample - loss: 1.7682 - val_loss: 0.9307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 22:48:35.399667 140735763825472 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\n",
      "0.9307292781829833\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "  128/60000 [..............................]\n",
      " - ETA: 56s - loss: 2.7554\n",
      "\n",
      " 1152/60000 [..............................]\n",
      " - ETA: 8s - loss: 2.4448 \n",
      "\b\n",
      " 2304/60000 [>.............................]\n",
      " - ETA: 5s - loss: 2.2362\n",
      "\b\n",
      " 3584/60000 [>.............................]\n",
      " - ETA: 4s - loss: 2.0663\n",
      "\b\n",
      " 4864/60000 [=>............................]\n",
      " - ETA: 3s - loss: 1.9279\n",
      "\b\n",
      " 6144/60000 [==>...........................]\n",
      " - ETA: 3s - loss: 1.7939\n",
      "\b\n",
      " 7296/60000 [==>...........................]\n",
      " - ETA: 3s - loss: 1.6974\n",
      "\b\n",
      " 8320/60000 [===>..........................]\n",
      " - ETA: 3s - loss: 1.6274\n",
      "\b\n",
      " 9216/60000 [===>..........................]\n",
      " - ETA: 2s - loss: 1.5600\n",
      "\b\n",
      "10112/60000 [====>.........................]\n",
      " - ETA: 2s - loss: 1.5032\n",
      "\b\n",
      "11008/60000 [====>.........................]\n",
      " - ETA: 2s - loss: 1.4584\n",
      "\b\n",
      "12032/60000 [=====>........................]\n",
      " - ETA: 2s - loss: 1.4088\n",
      "\b\n",
      "13056/60000 [=====>........................]\n",
      " - ETA: 2s - loss: 1.3598\n",
      "\b\n",
      "14464/60000 [======>.......................]\n",
      " - ETA: 2s - loss: 1.3047\n",
      "\b\n",
      "15872/60000 [======>.......................]\n",
      " - ETA: 2s - loss: 1.2598\n",
      "\b\n",
      "17152/60000 [=======>......................]\n",
      " - ETA: 2s - loss: 1.2199\n",
      "\b\n",
      "18432/60000 [========>.....................]\n",
      " - ETA: 2s - loss: 1.1848\n",
      "\b\n",
      "19712/60000 [========>.....................]\n",
      " - ETA: 2s - loss: 1.1550\n",
      "\b\n",
      "20992/60000 [=========>....................]\n",
      " - ETA: 1s - loss: 1.1270\n",
      "\b\n",
      "22272/60000 [==========>...................]\n",
      " - ETA: 1s - loss: 1.1001\n",
      "\b\n",
      "23552/60000 [==========>...................]\n",
      " - ETA: 1s - loss: 1.0757\n",
      "\b\n",
      "24832/60000 [===========>..................]\n",
      " - ETA: 1s - loss: 1.0519\n",
      "\b\n",
      "26112/60000 [============>.................]\n",
      " - ETA: 1s - loss: 1.0342\n",
      "\b\n",
      "27264/60000 [============>.................]\n",
      " - ETA: 1s - loss: 1.0157\n",
      "\b\n",
      "28416/60000 [=============>................]\n",
      " - ETA: 1s - loss: 0.9984\n",
      "\b\n",
      "29568/60000 [=============>................]\n",
      " - ETA: 1s - loss: 0.9809\n",
      "\b\n",
      "30720/60000 [==============>...............]\n",
      " - ETA: 1s - loss: 0.9651\n",
      "\b\n",
      "31872/60000 [==============>...............]\n",
      " - ETA: 1s - loss: 0.9501\n",
      "\b\n",
      "32768/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 0.9402\n",
      "\b\n",
      "33664/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 0.9297\n",
      "\b\n",
      "34304/60000 [================>.............]\n",
      " - ETA: 1s - loss: 0.9237\n",
      "\b\n",
      "35072/60000 [================>.............]\n",
      " - ETA: 1s - loss: 0.9177\n",
      "\b\n",
      "36096/60000 [=================>............]\n",
      " - ETA: 1s - loss: 0.9088\n",
      "\b\n",
      "37376/60000 [=================>............]\n",
      " - ETA: 1s - loss: 0.8972\n",
      "\b\n",
      "38528/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 0.8865\n",
      "\b\n",
      "39808/60000 [==================>...........]\n",
      " - ETA: 0s - loss: 0.8746\n",
      "\b\n",
      "41088/60000 [===================>..........]\n",
      " - ETA: 0s - loss: 0.8636\n",
      "\b\n",
      "42368/60000 [====================>.........]\n",
      " - ETA: 0s - loss: 0.8545\n",
      "\b\n",
      "43776/60000 [====================>.........]\n",
      " - ETA: 0s - loss: 0.8448\n",
      "\b\n",
      "45056/60000 [=====================>........]\n",
      " - ETA: 0s - loss: 0.8355\n",
      "\b\n",
      "46464/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 0.8241\n",
      "\b\n",
      "47872/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 0.8144\n",
      "\b\n",
      "49152/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 0.8069\n",
      "\b\n",
      "50432/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 0.7996\n",
      "\b\n",
      "51584/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 0.7927\n",
      "\b\n",
      "52736/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 0.7861\n",
      "\b\n",
      "54016/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 0.7785\n",
      "\b\n",
      "55296/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 0.7705\n",
      "\b\n",
      "56704/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 0.7631\n",
      "\b\n",
      "57856/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 0.7568\n",
      "\b\n",
      "59008/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.7504\n",
      "\b\n",
      "60000/60000 [==============================]\n",
      " - 3s 54us/sample - loss: 0.7459 - val_loss: 0.2291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 22:48:39.731167 140735763825472 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\n",
      "0.22913656501471996\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "  128/60000 [..............................]\n",
      " - ETA: 1:00 - loss: 2.5028\n",
      "\b\n",
      "  896/60000 [..............................]\n",
      " - ETA: 12s - loss: 2.0000 \n",
      "\n",
      " 1024/60000 [..............................]\n",
      " - ETA: 15s - loss: 1.9069\n",
      "\n",
      " 1664/60000 [..............................]\n",
      " - ETA: 11s - loss: 1.5613\n",
      "\n",
      " 2432/60000 [>.............................]\n",
      " - ETA: 8s - loss: 1.3332 \n",
      "\b\n",
      " 3200/60000 [>.............................]\n",
      " - ETA: 7s - loss: 1.1617\n",
      "\b\n",
      " 3968/60000 [>.............................]\n",
      " - ETA: 6s - loss: 1.0544\n",
      "\b\n",
      " 4736/60000 [=>............................]\n",
      " - ETA: 6s - loss: 0.9721\n",
      "\b\n",
      " 5504/60000 [=>............................]\n",
      " - ETA: 5s - loss: 0.9054\n",
      "\b\n",
      " 6400/60000 [==>...........................]\n",
      " - ETA: 5s - loss: 0.8493\n",
      "\b\n",
      " 7168/60000 [==>...........................]\n",
      " - ETA: 5s - loss: 0.8055\n",
      "\b\n",
      " 8192/60000 [===>..........................]\n",
      " - ETA: 4s - loss: 0.7560\n",
      "\b\n",
      " 9216/60000 [===>..........................]\n",
      " - ETA: 4s - loss: 0.7174\n",
      "\b\n",
      "10112/60000 [====>.........................]\n",
      " - ETA: 4s - loss: 0.6894\n",
      "\b\n",
      "10752/60000 [====>.........................]\n",
      " - ETA: 4s - loss: 0.6678\n",
      "\b\n",
      "11520/60000 [====>.........................]\n",
      " - ETA: 4s - loss: 0.6491\n",
      "\b\n",
      "12288/60000 [=====>........................]\n",
      " - ETA: 4s - loss: 0.6306\n",
      "\b\n",
      "13056/60000 [=====>........................]\n",
      " - ETA: 3s - loss: 0.6112\n",
      "\b\n",
      "13824/60000 [=====>........................]\n",
      " - ETA: 3s - loss: 0.5956\n",
      "\b\n",
      "14592/60000 [======>.......................]\n",
      " - ETA: 3s - loss: 0.5822\n",
      "\b\n",
      "15360/60000 [======>.......................]\n",
      " - ETA: 3s - loss: 0.5705\n",
      "\b\n",
      "16256/60000 [=======>......................]\n",
      " - ETA: 3s - loss: 0.5543\n",
      "\b\n",
      "17152/60000 [=======>......................]\n",
      " - ETA: 3s - loss: 0.5413\n",
      "\b\n",
      "18048/60000 [========>.....................]\n",
      " - ETA: 3s - loss: 0.5279\n",
      "\b\n",
      "18944/60000 [========>.....................]\n",
      " - ETA: 3s - loss: 0.5173\n",
      "\b\n",
      "19584/60000 [========>.....................]\n",
      " - ETA: 3s - loss: 0.5083\n",
      "\b\n",
      "20352/60000 [=========>....................]\n",
      " - ETA: 3s - loss: 0.4998\n",
      "\b\n",
      "21120/60000 [=========>....................]\n",
      " - ETA: 3s - loss: 0.4909\n",
      "\b\n",
      "21888/60000 [=========>....................]\n",
      " - ETA: 2s - loss: 0.4831\n",
      "\b\n",
      "22912/60000 [==========>...................]\n",
      " - ETA: 2s - loss: 0.4752\n",
      "\b\n",
      "23936/60000 [==========>...................]\n",
      " - ETA: 2s - loss: 0.4673\n",
      "\b\n",
      "24960/60000 [===========>..................]\n",
      " - ETA: 2s - loss: 0.4562\n",
      "\b\n",
      "25984/60000 [===========>..................]\n",
      " - ETA: 2s - loss: 0.4474\n",
      "\b\n",
      "27008/60000 [============>.................]\n",
      " - ETA: 2s - loss: 0.4393\n",
      "\b\n",
      "28032/60000 [=============>................]\n",
      " - ETA: 2s - loss: 0.4306\n",
      "\b\n",
      "29056/60000 [=============>................]\n",
      " - ETA: 2s - loss: 0.4228\n",
      "\b\n",
      "30080/60000 [==============>...............]\n",
      " - ETA: 2s - loss: 0.4166\n",
      "\b\n",
      "31104/60000 [==============>...............]\n",
      " - ETA: 2s - loss: 0.4105\n",
      "\b\n",
      "32000/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 0.4051\n",
      "\b\n",
      "32768/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 0.4004\n",
      "\b\n",
      "33536/60000 [===============>..............]\n",
      " - ETA: 1s - loss: 0.3961\n",
      "\b\n",
      "34304/60000 [================>.............]\n",
      " - ETA: 1s - loss: 0.3913\n",
      "\b\n",
      "35072/60000 [================>.............]\n",
      " - ETA: 1s - loss: 0.3891\n",
      "\b\n",
      "35840/60000 [================>.............]\n",
      " - ETA: 1s - loss: 0.3854\n",
      "\b\n",
      "36608/60000 [=================>............]\n",
      " - ETA: 1s - loss: 0.3821\n",
      "\b\n",
      "37504/60000 [=================>............]\n",
      " - ETA: 1s - loss: 0.3772\n",
      "\b\n",
      "38272/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 0.3734\n",
      "\b\n",
      "39040/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 0.3703\n",
      "\b\n",
      "39936/60000 [==================>...........]\n",
      " - ETA: 1s - loss: 0.3665\n",
      "\b\n",
      "40832/60000 [===================>..........]\n",
      " - ETA: 1s - loss: 0.3634\n",
      "\b\n",
      "41600/60000 [===================>..........]\n",
      " - ETA: 1s - loss: 0.3610\n",
      "\b\n",
      "42368/60000 [====================>.........]\n",
      " - ETA: 1s - loss: 0.3572\n",
      "\b\n",
      "43136/60000 [====================>.........]\n",
      " - ETA: 1s - loss: 0.3546\n",
      "\b\n",
      "43776/60000 [====================>.........]\n",
      " - ETA: 1s - loss: 0.3520\n",
      "\b\n",
      "44416/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 0.3495\n",
      "\b\n",
      "45056/60000 [=====================>........]\n",
      " - ETA: 1s - loss: 0.3468\n",
      "\b\n",
      "45824/60000 [=====================>........]\n",
      " - ETA: 0s - loss: 0.3437\n",
      "\b\n",
      "46464/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 0.3411\n",
      "\b\n",
      "47104/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 0.3384\n",
      "\b\n",
      "47744/60000 [======================>.......]\n",
      " - ETA: 0s - loss: 0.3360\n",
      "\b\n",
      "48640/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 0.3329\n",
      "\b\n",
      "49280/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 0.3301\n",
      "\b\n",
      "49920/60000 [=======================>......]\n",
      " - ETA: 0s - loss: 0.3280\n",
      "\b\n",
      "50560/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 0.3254\n",
      "\b\n",
      "51200/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 0.3237\n",
      "\b\n",
      "51840/60000 [========================>.....]\n",
      " - ETA: 0s - loss: 0.3214\n",
      "\b\n",
      "52608/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 0.3193\n",
      "\b\n",
      "53248/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 0.3174\n",
      "\b\n",
      "53888/60000 [=========================>....]\n",
      " - ETA: 0s - loss: 0.3159\n",
      "\b\n",
      "54656/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 0.3134\n",
      "\b\n",
      "55296/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 0.3115\n",
      "\b\n",
      "55936/60000 [==========================>...]\n",
      " - ETA: 0s - loss: 0.3095\n",
      "\b\n",
      "56576/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 0.3079\n",
      "\b\n",
      "57216/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 0.3058\n",
      "\b\n",
      "57856/60000 [===========================>..]\n",
      " - ETA: 0s - loss: 0.3039\n",
      "\b\n",
      "58624/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.3019\n",
      "\b\n",
      "59264/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.3005\n",
      "\b\n",
      "59904/60000 [============================>.]\n",
      " - ETA: 0s - loss: 0.2990\n",
      "\b\n",
      "60000/60000 [==============================]\n",
      " - 5s 80us/sample - loss: 0.2988 - val_loss: 0.1356\n",
      "\n",
      "Test accuracy:\n",
      "0.1355805284306407\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5, verbose=False,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='03_hyperparameter_optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "10000/10000 [==============================] - 0s 47us/sample - loss: 1.8748\n",
      "1.8747559463500976\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activation': 1,\n",
       " 'Dense': 1,\n",
       " 'Dropout': 0.7371698374615214,\n",
       " 'Dropout_1': 0.6517968154887782,\n",
       " 'batch_size': 1,\n",
       " 'optimizer': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/keras-team/autokeras/raw/master/logo.png?raw=true\" width=\"40%\">\n",
    "> The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models.\n",
    "\n",
    "https://github.com/keras-team/autokeras\n",
    "\n",
    "This competes with Google's hosted service called AutoML (https://cloud.google.com/automl/).\n",
    "\n",
    "There are more complex ways to train deep networks, such as using genetic algorithms or deep learning itself!  See \"Learning to learn by gradient descent by gradient descent\" (https://arxiv.org/abs/1606.04474)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
