{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Course, Bogotá, Colombia  (&copy; Josh Bloom; June 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://en.proft.me/media/science/ml_svlw.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning with scikit-learn\n",
    "\n",
    "Make sure you have version >= 0.19 installed\n",
    "\n",
    "```\n",
    "conda update scikit-learn -y\n",
    "# or...\n",
    "# pip install scikit-learn\n",
    "```\n",
    "\n",
    "See https://scikit-learn.org/stable/\n",
    "\n",
    "also: also: `mlpy`, `orange`, `keras`, `nolearn`, `tensorflow`, `astroML`, … "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://1.bp.blogspot.com/-ME24ePzpzIM/UQLWTwurfXI/AAAAAAAAANw/W3EETIroA80/s1600/drop_shadows_background.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Regression\n",
    "\n",
    "Use training set of $(\\vec x,y)$ pairs to learn to predict $y$ for new $\\vec x$\n",
    "\n",
    "**Regression** - predicting *continuous* outcome ($y$) variable from a vector of input features ($\\vec x$)\n",
    "\n",
    "- Linear Regression:  `linear_model.LinearRegression`\n",
    "- Lasso & Ridge Reg.:  `linear_model.Lasso` / `linear_model.Ridge`\n",
    "- Gaussian Process Regression: `gaussian_process.GaussianProcess`\n",
    "- Nearest Neighbor Regression:  `neighbors.KNeighborsRegressor`\n",
    "- Support Vector Regression:   `svm.SVR`\n",
    "- Regression Trees:  `tree.DecisionTreeRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression ## \n",
    "Let's take a look at the famous Boston Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston() # Boston house-prices\n",
    "X = boston['data']   # 13 features (e.g. crime, # rooms, age, etc.)\n",
    "Y = boston['target'] # response (median house price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"feature vector shape=\", X.shape)\n",
    "print(\"class shape=\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.feature_names)\n",
    "print(type(boston.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some data (Y axis is what we want to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(12,6))\n",
    "ax1.scatter(X[:,11],Y)\n",
    "ax2.scatter(X[:,10],Y)\n",
    "ax3.scatter(X[:,9],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "sns.set_context(\"poster\")\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "df = pd.DataFrame(X,columns=boston.feature_names)\n",
    "df[\"target\"]  = boston['target']\n",
    "col = cm.viridis(Y/max(Y))\n",
    "g= sns.pairplot(df[['AGE','DIS','RAD','TAX']], \n",
    "                plot_kws=dict(s=80*(Y/max(Y))**3,  color=col, edgecolor=None, alpha=0.7))\n",
    "\n",
    "# make a colorbar\n",
    "cmap = matplotlib.cm.ScalarMappable(\n",
    "      norm = colors.Normalize(min(Y), min(Y)), \n",
    "      cmap = plt.get_cmap('viridis'))\n",
    "\n",
    "cmap.set_array([]) # or alternatively cmap._A = []\n",
    "fig.colorbar(cmap, cax = fig.add_axes([.98, .4, .01, .2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model Fitting\n",
    "\n",
    "We need to create a **training set** and a **testing set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half of data\n",
    "import math\n",
    "half = math.floor(len(Y)/2)\n",
    "train_X = X[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X[half:]\n",
    "test_Y = Y[half:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Linear Regression **\n",
    "\n",
    "The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the input variables. In mathematical notion, if $\\hat{y}$ is the predicted value.\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
    "Across the module, we designate the vector $w = (w_1,\n",
    "..., w_p)$ as `coef_` and $w_0$ as `intercept_`.\n",
    "To perform classification with generalized linear models, see Logistic regression.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the prediction\n",
    "Y_lr_pred = clf.predict(test_X)\n",
    "\n",
    "# how well did we do?\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_Y,Y_lr_pred) ; print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(test_Y,Y_lr_pred - test_Y,'o')\n",
    "ax.set_title(\"Linear Regression Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($1,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *k*-Nearest Neighbor (KNN) Regression **\n",
    "\n",
    "\"The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data (possibly transformed into a fast indexing structure such as a Ball Tree or KD Tree.).\"\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_regression_001.png\">\n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "# many methods work better on scaled X\n",
    "X_scaled = preprocessing.scale(X) \n",
    "clf1 = neighbors.KNeighborsRegressor(5)\n",
    "train_X = X_scaled[:half]\n",
    "test_X = X_scaled[half:]\n",
    "clf1.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_knn_pred = clf1.predict(test_X)\n",
    "mse = mean_squared_error(test_Y,Y_knn_pred) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(test_Y, Y_knn_pred - test_Y,'o',alpha=0.4)\n",
    "ax.set_title(\"k-NN Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($1,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what other datasets are readily available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these we need to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_house = datasets.california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data = cal_house.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cal_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cal_data['data'] # 8 features \n",
    "Y = cal_data['target'] # response (median house price)\n",
    "half = math.floor(len(Y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# remember: many methods work better on scaled X\n",
    "X_scaled = preprocessing.scale(X) \n",
    "train_X = X_scaled[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X_scaled[half:]\n",
    "test_Y = Y[half:]\n",
    "clf1 = neighbors.KNeighborsRegressor(15)\n",
    "clf1.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "Y_knn_pred = clf1.predict(test_X)\n",
    "mse = mean_squared_error(test_Y,Y_knn_pred) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(test_Y, Y_knn_pred - test_Y,alpha=0.2,edgecolors=None)\n",
    "ax.set_title(\"k-NN Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True log normalized Median House Price\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")\n",
    "ax.set_xlim(0,5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Estimation & Model Selection\n",
    "\n",
    "**Q**: How will our model perform on future data?\n",
    "\n",
    "So far, we’ve split the data, using one set to train the model and the other to test its performance\n",
    "\n",
    "This train-test strategy avoids over-fitting to the sample on hand, but wastes data & can produce poor error estimates.\n",
    "\n",
    "cf http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "### model selection: cross-validation\n",
    "\n",
    "\n",
    "- *K-fold CV* - randomly split the training data into K folds.  For each $k=1,...,K$, train model only on the data not in fold $k$ & predict for data in fold $k$.  Compute performance metric over CV predictions.\n",
    "\n",
    "- *Leave-one-out (LOO) CV* - K-fold CV with  K = number of training points.\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUWvg9caKz1OO7opS2Ji3Z7OwOFkLCrg2WsB/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://i.stack.imgur.com/YWgro.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.GridSearchCV # hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X = boston['data'] ; y = boston['target']\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def print_cv_score_summary(model, xx, yy, cv):\n",
    "    scores = cross_val_score(model, xx, yy, cv=cv, n_jobs=1)\n",
    "    print(\"mean: {:3f}, stdev: {:3f}\".format(\n",
    "        np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "print_cv_score_summary(clf, X, y,\n",
    "                       cv=model_selection.KFold(5, shuffle=True, random_state = 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
